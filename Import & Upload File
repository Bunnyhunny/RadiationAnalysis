#Upload file: 
#Go to psftp
open 129.150.122.140

#Login your username and password

put safecast.zip

put incd.csv

put BYAREA.txt



#Go to putty

#check if the files are uploaded to Hadoop
ls -al 

#unzip the file that we uploaded in Hadoop
unzip safecast.zip



hdfs dfs -mkdir radiation
hdfs dfs -mkdir radiation/data
hdfs dfs -mkdir radiation/data/masterfile
hdfs dfs -mkdir radiation/data/cancerfile1
hdfs dfs -mkdir radiation/data/cancerfile2
hdfs dfs -ls radiation
hdfs dfs -chmod -R o+w .



hdfs dfs -put measurements.csv radiation/data/masterfile
hdfs dfs -ls radiation/data/masterfile

hdfs dfs -put incd.csv radiation/data/cancerfile1
hdfs dfs -ls radiation/data/cancerfile1

hdfs dfs -put BYAREA.txt radiation/data/cancerfile2
hdfs dfs -ls radiation/data/cancerfile2


!connect jdbc:hive2://cis5200spr19-bdcsce-2.compute-608214094.oraclecloud.internal:2181,cis5200spr19-bdcsce-3.compute-608214094.oraclecloud.internal:2181,cis5200spr19-bdcsce-4.compute-608214094.oraclecloud.internal:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2?tez.queue.name=interactive bdcsce_admin

# create database
create database group2;  
use group2;


